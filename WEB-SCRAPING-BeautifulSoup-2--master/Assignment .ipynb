{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTIONS\n",
    "\n",
    "### Book Details\n",
    "\n",
    "Find and print the details of all books which are present on first 2 pages of this website\n",
    ".\n",
    "All details include - Title of the book, book page url, Price (in float, without any currency or extra symbol), and quantity in stock (in integer). Save all the details in a dataframe and print in the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quantity in Stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>http://books.toscrape.com/catalogue/a-light-in...</td>\n",
       "      <td>51.77</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>http://books.toscrape.com/catalogue/tipping-th...</td>\n",
       "      <td>53.74</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Soumission</td>\n",
       "      <td>http://books.toscrape.com/catalogue/soumission...</td>\n",
       "      <td>50.10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>http://books.toscrape.com/catalogue/sharp-obje...</td>\n",
       "      <td>47.82</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>http://books.toscrape.com/catalogue/sapiens-a-...</td>\n",
       "      <td>54.23</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>The Requiem Red</td>\n",
       "      <td>http://books.toscrape.com/catalogue/the-requie...</td>\n",
       "      <td>22.65</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>The Dirty Little Secrets of Getting Your Dream...</td>\n",
       "      <td>http://books.toscrape.com/catalogue/the-dirty-...</td>\n",
       "      <td>33.34</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>The Coming Woman: A Novel Based on the Life of...</td>\n",
       "      <td>http://books.toscrape.com/catalogue/the-coming...</td>\n",
       "      <td>17.93</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>The Boys in the Boat: Nine Americans and Their...</td>\n",
       "      <td>http://books.toscrape.com/catalogue/the-boys-i...</td>\n",
       "      <td>22.60</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>The Black Maria</td>\n",
       "      <td>http://books.toscrape.com/catalogue/the-black-...</td>\n",
       "      <td>52.15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Starving Hearts (Triangular Trade Trilogy, #1)</td>\n",
       "      <td>http://books.toscrape.com/catalogue/starving-h...</td>\n",
       "      <td>13.99</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Shakespeare's Sonnets</td>\n",
       "      <td>http://books.toscrape.com/catalogue/shakespear...</td>\n",
       "      <td>20.66</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Set Me Free</td>\n",
       "      <td>http://books.toscrape.com/catalogue/set-me-fre...</td>\n",
       "      <td>17.46</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Scott Pilgrim's Precious Little Life (Scott Pi...</td>\n",
       "      <td>http://books.toscrape.com/catalogue/scott-pilg...</td>\n",
       "      <td>52.29</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Rip it Up and Start Again</td>\n",
       "      <td>http://books.toscrape.com/catalogue/rip-it-up-...</td>\n",
       "      <td>35.02</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Our Band Could Be Your Life: Scenes from the A...</td>\n",
       "      <td>http://books.toscrape.com/catalogue/our-band-c...</td>\n",
       "      <td>57.25</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Olio</td>\n",
       "      <td>http://books.toscrape.com/catalogue/olio_984/i...</td>\n",
       "      <td>23.88</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Mesaerion: The Best Science Fiction Stories 18...</td>\n",
       "      <td>http://books.toscrape.com/catalogue/mesaerion-...</td>\n",
       "      <td>37.59</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Libertarianism for Beginners</td>\n",
       "      <td>http://books.toscrape.com/catalogue/libertaria...</td>\n",
       "      <td>51.33</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>It's Only the Himalayas</td>\n",
       "      <td>http://books.toscrape.com/catalogue/its-only-t...</td>\n",
       "      <td>45.17</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>In Her Wake</td>\n",
       "      <td>http://books.toscrape.com/catalogue/in-her-wak...</td>\n",
       "      <td>12.84</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>How Music Works</td>\n",
       "      <td>http://books.toscrape.com/catalogue/how-music-...</td>\n",
       "      <td>37.32</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Foolproof Preserving: A Guide to Small Batch J...</td>\n",
       "      <td>http://books.toscrape.com/catalogue/foolproof-...</td>\n",
       "      <td>30.52</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Chase Me (Paris Nights #2)</td>\n",
       "      <td>http://books.toscrape.com/catalogue/chase-me-p...</td>\n",
       "      <td>25.27</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Black Dust</td>\n",
       "      <td>http://books.toscrape.com/catalogue/black-dust...</td>\n",
       "      <td>34.53</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Birdsong: A Story in Pictures</td>\n",
       "      <td>http://books.toscrape.com/catalogue/birdsong-a...</td>\n",
       "      <td>54.64</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>America's Cradle of Quarterbacks: Western Penn...</td>\n",
       "      <td>http://books.toscrape.com/catalogue/americas-c...</td>\n",
       "      <td>22.50</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Aladdin and His Wonderful Lamp</td>\n",
       "      <td>http://books.toscrape.com/catalogue/aladdin-an...</td>\n",
       "      <td>53.13</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Worlds Elsewhere: Journeys Around Shakespeare√¢...</td>\n",
       "      <td>http://books.toscrape.com/catalogue/worlds-els...</td>\n",
       "      <td>40.30</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Wall and Piece</td>\n",
       "      <td>http://books.toscrape.com/catalogue/wall-and-p...</td>\n",
       "      <td>44.18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>The Four Agreements: A Practical Guide to Pers...</td>\n",
       "      <td>http://books.toscrape.com/catalogue/the-four-a...</td>\n",
       "      <td>17.66</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>The Five Love Languages: How to Express Heartf...</td>\n",
       "      <td>http://books.toscrape.com/catalogue/the-five-l...</td>\n",
       "      <td>31.05</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>The Elephant Tree</td>\n",
       "      <td>http://books.toscrape.com/catalogue/the-elepha...</td>\n",
       "      <td>23.82</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>The Bear and the Piano</td>\n",
       "      <td>http://books.toscrape.com/catalogue/the-bear-a...</td>\n",
       "      <td>36.89</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>Sophie's World</td>\n",
       "      <td>http://books.toscrape.com/catalogue/sophies-wo...</td>\n",
       "      <td>15.94</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Penny Maybe</td>\n",
       "      <td>http://books.toscrape.com/catalogue/penny-mayb...</td>\n",
       "      <td>33.29</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Maude (1883-1993):She Grew Up with the country</td>\n",
       "      <td>http://books.toscrape.com/catalogue/maude-1883...</td>\n",
       "      <td>18.02</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>In a Dark, Dark Wood</td>\n",
       "      <td>http://books.toscrape.com/catalogue/in-a-dark-...</td>\n",
       "      <td>19.63</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>Behind Closed Doors</td>\n",
       "      <td>http://books.toscrape.com/catalogue/behind-clo...</td>\n",
       "      <td>52.22</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>You can't bury them all: Poems</td>\n",
       "      <td>http://books.toscrape.com/catalogue/you-cant-b...</td>\n",
       "      <td>33.63</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                                A Light in the Attic   \n",
       "1                                  Tipping the Velvet   \n",
       "2                                          Soumission   \n",
       "3                                       Sharp Objects   \n",
       "4               Sapiens: A Brief History of Humankind   \n",
       "5                                     The Requiem Red   \n",
       "6   The Dirty Little Secrets of Getting Your Dream...   \n",
       "7   The Coming Woman: A Novel Based on the Life of...   \n",
       "8   The Boys in the Boat: Nine Americans and Their...   \n",
       "9                                     The Black Maria   \n",
       "10     Starving Hearts (Triangular Trade Trilogy, #1)   \n",
       "11                              Shakespeare's Sonnets   \n",
       "12                                        Set Me Free   \n",
       "13  Scott Pilgrim's Precious Little Life (Scott Pi...   \n",
       "14                          Rip it Up and Start Again   \n",
       "15  Our Band Could Be Your Life: Scenes from the A...   \n",
       "16                                               Olio   \n",
       "17  Mesaerion: The Best Science Fiction Stories 18...   \n",
       "18                       Libertarianism for Beginners   \n",
       "19                            It's Only the Himalayas   \n",
       "20                                        In Her Wake   \n",
       "21                                    How Music Works   \n",
       "22  Foolproof Preserving: A Guide to Small Batch J...   \n",
       "23                         Chase Me (Paris Nights #2)   \n",
       "24                                         Black Dust   \n",
       "25                      Birdsong: A Story in Pictures   \n",
       "26  America's Cradle of Quarterbacks: Western Penn...   \n",
       "27                     Aladdin and His Wonderful Lamp   \n",
       "28  Worlds Elsewhere: Journeys Around Shakespeare√¢...   \n",
       "29                                     Wall and Piece   \n",
       "30  The Four Agreements: A Practical Guide to Pers...   \n",
       "31  The Five Love Languages: How to Express Heartf...   \n",
       "32                                  The Elephant Tree   \n",
       "33                             The Bear and the Piano   \n",
       "34                                     Sophie's World   \n",
       "35                                        Penny Maybe   \n",
       "36     Maude (1883-1993):She Grew Up with the country   \n",
       "37                               In a Dark, Dark Wood   \n",
       "38                                Behind Closed Doors   \n",
       "39                     You can't bury them all: Poems   \n",
       "\n",
       "                                                 Link  Price  \\\n",
       "0   http://books.toscrape.com/catalogue/a-light-in...  51.77   \n",
       "1   http://books.toscrape.com/catalogue/tipping-th...  53.74   \n",
       "2   http://books.toscrape.com/catalogue/soumission...  50.10   \n",
       "3   http://books.toscrape.com/catalogue/sharp-obje...  47.82   \n",
       "4   http://books.toscrape.com/catalogue/sapiens-a-...  54.23   \n",
       "5   http://books.toscrape.com/catalogue/the-requie...  22.65   \n",
       "6   http://books.toscrape.com/catalogue/the-dirty-...  33.34   \n",
       "7   http://books.toscrape.com/catalogue/the-coming...  17.93   \n",
       "8   http://books.toscrape.com/catalogue/the-boys-i...  22.60   \n",
       "9   http://books.toscrape.com/catalogue/the-black-...  52.15   \n",
       "10  http://books.toscrape.com/catalogue/starving-h...  13.99   \n",
       "11  http://books.toscrape.com/catalogue/shakespear...  20.66   \n",
       "12  http://books.toscrape.com/catalogue/set-me-fre...  17.46   \n",
       "13  http://books.toscrape.com/catalogue/scott-pilg...  52.29   \n",
       "14  http://books.toscrape.com/catalogue/rip-it-up-...  35.02   \n",
       "15  http://books.toscrape.com/catalogue/our-band-c...  57.25   \n",
       "16  http://books.toscrape.com/catalogue/olio_984/i...  23.88   \n",
       "17  http://books.toscrape.com/catalogue/mesaerion-...  37.59   \n",
       "18  http://books.toscrape.com/catalogue/libertaria...  51.33   \n",
       "19  http://books.toscrape.com/catalogue/its-only-t...  45.17   \n",
       "20  http://books.toscrape.com/catalogue/in-her-wak...  12.84   \n",
       "21  http://books.toscrape.com/catalogue/how-music-...  37.32   \n",
       "22  http://books.toscrape.com/catalogue/foolproof-...  30.52   \n",
       "23  http://books.toscrape.com/catalogue/chase-me-p...  25.27   \n",
       "24  http://books.toscrape.com/catalogue/black-dust...  34.53   \n",
       "25  http://books.toscrape.com/catalogue/birdsong-a...  54.64   \n",
       "26  http://books.toscrape.com/catalogue/americas-c...  22.50   \n",
       "27  http://books.toscrape.com/catalogue/aladdin-an...  53.13   \n",
       "28  http://books.toscrape.com/catalogue/worlds-els...  40.30   \n",
       "29  http://books.toscrape.com/catalogue/wall-and-p...  44.18   \n",
       "30  http://books.toscrape.com/catalogue/the-four-a...  17.66   \n",
       "31  http://books.toscrape.com/catalogue/the-five-l...  31.05   \n",
       "32  http://books.toscrape.com/catalogue/the-elepha...  23.82   \n",
       "33  http://books.toscrape.com/catalogue/the-bear-a...  36.89   \n",
       "34  http://books.toscrape.com/catalogue/sophies-wo...  15.94   \n",
       "35  http://books.toscrape.com/catalogue/penny-mayb...  33.29   \n",
       "36  http://books.toscrape.com/catalogue/maude-1883...  18.02   \n",
       "37  http://books.toscrape.com/catalogue/in-a-dark-...  19.63   \n",
       "38  http://books.toscrape.com/catalogue/behind-clo...  52.22   \n",
       "39  http://books.toscrape.com/catalogue/you-cant-b...  33.63   \n",
       "\n",
       "    Quantity in Stock  \n",
       "0                  22  \n",
       "1                  20  \n",
       "2                  20  \n",
       "3                  20  \n",
       "4                  20  \n",
       "5                  19  \n",
       "6                  19  \n",
       "7                  19  \n",
       "8                  19  \n",
       "9                  19  \n",
       "10                 19  \n",
       "11                 19  \n",
       "12                 19  \n",
       "13                 19  \n",
       "14                 19  \n",
       "15                 19  \n",
       "16                 19  \n",
       "17                 19  \n",
       "18                 19  \n",
       "19                 19  \n",
       "20                 19  \n",
       "21                 19  \n",
       "22                 19  \n",
       "23                 19  \n",
       "24                 19  \n",
       "25                 19  \n",
       "26                 19  \n",
       "27                 19  \n",
       "28                 18  \n",
       "29                 18  \n",
       "30                 18  \n",
       "31                 18  \n",
       "32                 18  \n",
       "33                 18  \n",
       "34                 18  \n",
       "35                 18  \n",
       "36                 18  \n",
       "37                 18  \n",
       "38                 18  \n",
       "39                 17  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Print the required output in given format\n",
    "## You are given page links in variable allPages, use this\n",
    "## Column names of your dataframes should be as per given in the variable column_names\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "allPages = ['http://books.toscrape.com/catalogue/page-1.html',\n",
    "            'http://books.toscrape.com/catalogue/page-2.html']\n",
    "\n",
    "column_names = ['Title', 'Link', 'Price', 'Quantity in Stock']\n",
    "\n",
    "import re\n",
    "\n",
    "title = []\n",
    "prices = []\n",
    "quantity = []\n",
    "\n",
    "base_url = 'http://books.toscrape.com/catalogue/'\n",
    "all_books_urls = []\n",
    "\n",
    "for i in allPages:\n",
    "    res = requests.get(i)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    book = soup.find_all(class_ = 'product_pod')\n",
    "    \n",
    "    for j in book:\n",
    "        book_url = base_url + j.h3.a['href']\n",
    "        all_books_urls.append(book_url)\n",
    "\n",
    "for book in all_books_urls:\n",
    "    r = requests.get(book)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    title.append(soup.h1.string)\n",
    "    price = soup.find(class_ = 'price_color').string\n",
    "    qty = soup.find(class_ = 'instock availability')\n",
    "    qty = qty.contents[-1].strip()\n",
    "    prices.append(float(re.search('[\\d.]+', price).group()))\n",
    "    quantity.append(int(re.search('\\d+', qty).group()))\n",
    "    \n",
    "all_book_details = []\n",
    "\n",
    "for i in range(len(all_books_urls)):\n",
    "    all_book_details.append([title[i], all_books_urls[i], prices[i], quantity[i]])\n",
    "all_book_details\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(all_book_details, columns = column_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Light in the Attic http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html 51.77 22\n",
      "Tipping the Velvet http://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html 53.74 20\n",
      "Soumission http://books.toscrape.com/catalogue/soumission_998/index.html 50.1 20\n",
      "Sharp Objects http://books.toscrape.com/catalogue/sharp-objects_997/index.html 47.82 20\n",
      "Sapiens: A Brief History of Humankind http://books.toscrape.com/catalogue/sapiens-a-brief-history-of-humankind_996/index.html 54.23 20\n",
      "The Requiem Red http://books.toscrape.com/catalogue/the-requiem-red_995/index.html 22.65 19\n",
      "The Dirty Little Secrets of Getting Your Dream Job http://books.toscrape.com/catalogue/the-dirty-little-secrets-of-getting-your-dream-job_994/index.html 33.34 19\n",
      "The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull http://books.toscrape.com/catalogue/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html 17.93 19\n",
      "The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics http://books.toscrape.com/catalogue/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html 22.6 19\n",
      "The Black Maria http://books.toscrape.com/catalogue/the-black-maria_991/index.html 52.15 19\n",
      "Starving Hearts (Triangular Trade Trilogy, #1) http://books.toscrape.com/catalogue/starving-hearts-triangular-trade-trilogy-1_990/index.html 13.99 19\n",
      "Shakespeare's Sonnets http://books.toscrape.com/catalogue/shakespeares-sonnets_989/index.html 20.66 19\n",
      "Set Me Free http://books.toscrape.com/catalogue/set-me-free_988/index.html 17.46 19\n",
      "Scott Pilgrim's Precious Little Life (Scott Pilgrim #1) http://books.toscrape.com/catalogue/scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html 52.29 19\n",
      "Rip it Up and Start Again http://books.toscrape.com/catalogue/rip-it-up-and-start-again_986/index.html 35.02 19\n",
      "Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991 http://books.toscrape.com/catalogue/our-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html 57.25 19\n",
      "Olio http://books.toscrape.com/catalogue/olio_984/index.html 23.88 19\n",
      "Mesaerion: The Best Science Fiction Stories 1800-1849 http://books.toscrape.com/catalogue/mesaerion-the-best-science-fiction-stories-1800-1849_983/index.html 37.59 19\n",
      "Libertarianism for Beginners http://books.toscrape.com/catalogue/libertarianism-for-beginners_982/index.html 51.33 19\n",
      "It's Only the Himalayas http://books.toscrape.com/catalogue/its-only-the-himalayas_981/index.html 45.17 19\n",
      "In Her Wake http://books.toscrape.com/catalogue/in-her-wake_980/index.html 12.84 19\n",
      "How Music Works http://books.toscrape.com/catalogue/how-music-works_979/index.html 37.32 19\n",
      "Foolproof Preserving: A Guide to Small Batch Jams, Jellies, Pickles, Condiments, and More: A Foolproof Guide to Making Small Batch Jams, Jellies, Pickles, Condiments, and More http://books.toscrape.com/catalogue/foolproof-preserving-a-guide-to-small-batch-jams-jellies-pickles-condiments-and-more-a-foolproof-guide-to-making-small-batch-jams-jellies-pickles-condiments-and-more_978/index.html 30.52 19\n",
      "Chase Me (Paris Nights #2) http://books.toscrape.com/catalogue/chase-me-paris-nights-2_977/index.html 25.27 19\n",
      "Black Dust http://books.toscrape.com/catalogue/black-dust_976/index.html 34.53 19\n",
      "Birdsong: A Story in Pictures http://books.toscrape.com/catalogue/birdsong-a-story-in-pictures_975/index.html 54.64 19\n",
      "America's Cradle of Quarterbacks: Western Pennsylvania's Football Factory from Johnny Unitas to Joe Montana http://books.toscrape.com/catalogue/americas-cradle-of-quarterbacks-western-pennsylvanias-football-factory-from-johnny-unitas-to-joe-montana_974/index.html 22.5 19\n",
      "Aladdin and His Wonderful Lamp http://books.toscrape.com/catalogue/aladdin-and-his-wonderful-lamp_973/index.html 53.13 19\n",
      "Worlds Elsewhere: Journeys Around Shakespeare√¢¬Ä¬ôs Globe http://books.toscrape.com/catalogue/worlds-elsewhere-journeys-around-shakespeares-globe_972/index.html 40.3 18\n",
      "Wall and Piece http://books.toscrape.com/catalogue/wall-and-piece_971/index.html 44.18 18\n",
      "The Four Agreements: A Practical Guide to Personal Freedom http://books.toscrape.com/catalogue/the-four-agreements-a-practical-guide-to-personal-freedom_970/index.html 17.66 18\n",
      "The Five Love Languages: How to Express Heartfelt Commitment to Your Mate http://books.toscrape.com/catalogue/the-five-love-languages-how-to-express-heartfelt-commitment-to-your-mate_969/index.html 31.05 18\n",
      "The Elephant Tree http://books.toscrape.com/catalogue/the-elephant-tree_968/index.html 23.82 18\n",
      "The Bear and the Piano http://books.toscrape.com/catalogue/the-bear-and-the-piano_967/index.html 36.89 18\n",
      "Sophie's World http://books.toscrape.com/catalogue/sophies-world_966/index.html 15.94 18\n",
      "Penny Maybe http://books.toscrape.com/catalogue/penny-maybe_965/index.html 33.29 18\n",
      "Maude (1883-1993):She Grew Up with the country http://books.toscrape.com/catalogue/maude-1883-1993she-grew-up-with-the-country_964/index.html 18.02 18\n",
      "In a Dark, Dark Wood http://books.toscrape.com/catalogue/in-a-dark-dark-wood_963/index.html 19.63 18\n",
      "Behind Closed Doors http://books.toscrape.com/catalogue/behind-closed-doors_962/index.html 52.22 18\n",
      "You can't bury them all: Poems http://books.toscrape.com/catalogue/you-cant-bury-them-all-poems_961/index.html 33.63 17\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    print(df.loc[i,'Title'], df.loc[i,'Link'], df.loc[i,'Price'], df.loc[i,'Quantity in Stock'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the data of first 3 movies\n",
    "\n",
    "link - https://www.imdb.com/search/title?release_date=2018&sort=num_votes,desc&page=1&ref_=adv_nxt\n",
    "\n",
    "From this link,\n",
    "\n",
    "Find and print the name and genre of the first 3 titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avengers: Infinity War ; Action, Adventure, Sci-Fi            \n",
      "Black Panther ; Action, Adventure, Sci-Fi            \n",
      "Deadpool 2 ; Action, Adventure, Comedy            \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "response = requests.get('https://www.imdb.com/search/title/?release_date=2018&sort=num_votes,desc&page=1&ref_=adv_nxt')\n",
    "data = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "titles = data.find_all(class_ = \"lister-item-header\")\n",
    "genres = data.find_all(class_ = \"genre\")\n",
    "\n",
    "for i in range(3):\n",
    "    print(titles[i].a.string + ' ; ' + genres[i].string.strip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avengers: Infinity War ; Action, Adventure, Sci-Fi\n",
      "Black Panther ; Action, Adventure, Sci-Fi\n",
      "Deadpool 2 ; Action, Adventure, Comedy\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "response = requests.get('https://www.imdb.com/search/title/?release_date=2018&sort=num_votes,desc&page=1&ref_=adv_nxt')\n",
    "data = BeautifulSoup(response.text, 'html.parser')\n",
    "names = []\n",
    "genre = []\n",
    "c = 0 \n",
    "for i in data.select('.lister-item') :\n",
    "    if c < 3 :\n",
    "        name_title = i.select(\".lister-item-header a\")[0].text.strip()\n",
    "        names.append(name_title)\n",
    "        gr = i.find(\"span\", class_ = \"genre\").text.strip()\n",
    "        genre.append(gr)\n",
    "        c += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "for i in range(len(names)):\n",
    "    print(names[i], ';' ,genre[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### titles with most votes\n",
    "\n",
    "Link to use - https://www.imdb.com/search/title?release_date=2018&sort=num_votes,desc&page=1&ref_=adv_nxt\n",
    "\n",
    "Print the names of movies with highest number of votes from year 2010 to 2014\n",
    "\n",
    "Note : Print the titles line wise starting from year 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception\n",
      "Game of Thrones\n",
      "The Dark Knight Rises\n",
      "The Wolf of Wall Street\n",
      "Interstellar\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "titles = []\n",
    "for i in range(2010,2015) :\n",
    "    page = requests.get('https://www.imdb.com/search/title/?release_date=' + str(i) \n",
    "                        + '&sort=num_votes,desc&page=1&ref_=adv_nxt')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    title = soup.find(class_ = \"lister-item-header\")\n",
    "    titles.append(title.a.string)\n",
    "    \n",
    "for j in titles:\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### title with maximum duration\n",
    "\n",
    "Link to use - https://www.imdb.com/search/title?release_date=2018&sort=num_votes,desc&page=1&ref_=adv_nxt\n",
    "\n",
    "Out of the first 250 titles with highest number of votes in 2018,find which title has the maximum duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.imdb.com/search/title/?release_date=2018&sort=num_votes,desc&page=1&ref_=adv_nxt', 'https://www.imdb.com/search/title/?release_date=2018-01-01,2018-12-31&sort=num_votes,desc&start=51', 'https://www.imdb.com/search/title/?release_date=2018-01-01,2018-12-31&sort=num_votes,desc&start=101', 'https://www.imdb.com/search/title/?release_date=2018-01-01,2018-12-31&sort=num_votes,desc&start=151', 'https://www.imdb.com/search/title/?release_date=2018-01-01,2018-12-31&sort=num_votes,desc&start=201']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "first_5_pages = ['https://www.imdb.com/search/title/?release_date=2018&sort=num_votes,desc&page=1&ref_=adv_nxt']\n",
    "current_page = 'https://www.imdb.com/search/title/?release_date=2018&sort=num_votes,desc&page=1&ref_=adv_nxt'\n",
    "\n",
    "response = requests.get(current_page)\n",
    "\n",
    "pages = []\n",
    "\n",
    "base_url = 'https://www.imdb.com'\n",
    "for i in range(4):\n",
    "    data = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    next_page = data.find(class_ = \"lister-page-next next-page\")['href']\n",
    "    \n",
    "    next_page_url = base_url + next_page\n",
    "    first_5_pages.append(next_page_url)\n",
    "    \n",
    "    current_page = next_page_url\n",
    "    response = requests.get(current_page)\n",
    "    \n",
    "print(first_5_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149, 134, 119, 134, 90, 140, 143, 112, 130, 117, 136, 118, 147, 135, 115, 124, 128, 118, 127, 134, 100, 135, 119, 110, 119, 140, 141, 50, 100, 113, 107, 60, 135, 101, 102, 120, 114, 45, 112, 121, 141, 122, 117, 107, 133, 106, 96, 132, 90, 143, 100, 111, 105, 102, 130, 116, 128, 110, 102, 140, 60, 129, 60, 99, 110, 114, 118, 130, 42, 60, 102, 50, 60, 104, 117, 130, 139, 94, 421, 40, 45, 107, 116, 89, 121, 93, 121, 112, 110, 152, 104, 105, 50, 121, 97, 105, 152, 96, 97, 103, 95, 100, 122, 122, 101, 126, 110, 123, 155, 120, 85, 109, 89, 97, 95, 106, 104, 100, 96, 113, 105, 30, 148, 85, 30, 97, 109, 94, 105, 130, 30, 98, 85, 115, 98, 93, 119, 60, 116, 41, 124, 100, 60, 60, 60, 95, 128, 105, 112, 159, 125, 160, 105, 111, 90, 125, 96, 156, 30, 105, 124, 40, 94, 98, 126, 139, 122, 99, 60, 115, 107, 60, 90, 94, 97, 104, 133, 99, 164, 96, 133, 110, 43, 45, 94, 128, 85, 99, 111, 124, 143, 111, 101, 60, 97, 93, 113, 65, 95, 104, 111, 134, 94, 99, 60, 138, 121, 91, 164, 87, 98, 91, 60, 96, 95, 403, 110, 104, 45, 30, 100, 91, 120, 105, 103, 8, 148, 103, 43, 30, 43, 129, 192, 114, 92, 101, 140, 120, 90, 121, 138, 89, 43, 107, 96, 101, 105, 103, 109, 30]\n",
      "['Avengers: Infinity War', 'Black Panther', 'Deadpool 2', 'Bohemian Rhapsody', 'A Quiet Place', 'Ready Player One', 'Aquaman', 'Venom', 'Green Book', 'Spider-Man: Into the Spider-Verse', 'A Star Is Born', 'Ant-Man and the Wasp', 'Mission: Impossible - Fallout', 'Solo: A Star Wars Story', 'Annihilation', 'Bird Box', 'Jurassic World: Fallen Kingdom', 'Incredibles 2', 'Hereditary', 'Fantastic Beasts: The Crimes of Grindelwald', 'Game Night', 'BlacKkKlansman', 'Tomb Raider', \"Ocean's Eight\", 'The Favourite', 'Red Sparrow', 'First Man', 'The Haunting of Hill House', 'Upgrade', 'The Meg', 'Rampage', 'Altered Carbon', 'Roma', 'Isle of Dogs', 'Searching', 'Crazy Rich Asians', 'Bumblebee', 'You', 'Ralph Breaks the Internet: Wreck-It Ralph 2', 'The Equalizer 2', 'Bad Times at the El Royale', 'Sicario 2: Soldado', 'A Simple Favor', 'The Predator', 'The Ballad of Buster Scruggs', 'Halloween', 'The Nun', 'Vice', 'Black Mirror: Bandersnatch', 'The Maze Runner: The Death Cure', 'Tag', 'Pacific Rim: Uprising', 'The Commuter', 'Skyscraper', 'Creed 2', 'The Mule', 'Mortal Engines', 'Love, Simon', 'The Cloverfield Paradox', 'Den of Thieves', 'Bodyguard', 'Widows', 'Jack Ryan', \"To All the Boys I've Loved Before\", 'Overlord', 'Mamma Mia! Here We Go Again', 'Instant Family', 'Mary Poppins Returns', 'Killing Eve', 'Lost in Space', 'Blockers', 'Sacred Games', 'Chilling Adventures of Sabrina', 'Christopher Robin', 'The Spy Who Dumped Me', '12 Strong', 'Andhadhun', 'Mile 22', 'Sharp Objects', 'Maniac', 'Titans', 'Death Wish', 'Robin Hood', 'Johnny English Strikes Again', 'Mandy', 'Eighth Grade', 'Outlaw King', 'Sorry to Bother You', 'Enes Batur Hayal mi Ger√ßek mi?', 'Suspiria', 'Mowgli', 'The Kissing Booth', 'Narcos: Mexico', 'Shoplifters', 'Hotel Transylvania 3: Summer Vacation', 'Fifty Shades Freed', 'The House That Jack Built', 'Alpha', 'The First Purge', 'Insidious: The Last Key', 'Tully', 'Free Solo', 'Les fr√®res Sisters', 'Hunter Killer', 'Peppermint', 'Capharna√ºm', 'I Feel Pretty', 'Hotel Mumbai', 'Sanju', 'Beautiful Boy', 'The Grinch', 'Leave No Trace', 'Zimna wojna', 'Climax', 'Extinction', 'Can You Ever Forgive Me?', 'The Christmas Chronicles', 'Truth or Dare', 'Adrift', 'How It Ends', 'The House with a Clock in its Wall', 'Cobra Kai', 'Beoning', 'Mid90s', 'Disenchantment', 'When We First Met', 'A Wrinkle in Time', 'Hotel Artemis', 'Set It Up', 'Apostle', 'Barry', 'Arctic', 'Den skyldige', \"The Girl In The Spider's Web\", 'Unsane', 'The Old Man & The Gun', 'If Beale Street Could Talk', '√âlite', 'American Animals', 'O Mecanismo', 'Mary Queen of Scots', 'Anon', 'Castle Rock', 'The Terror', 'The Alienist', 'Peter Rabbit', 'Durante la tormenta', 'Sierra Burgess Is a Loser', 'Overboard', 'Dragged Across Concrete', 'Hold the Dark', 'Race 3', 'Life of the Party', 'Night School', 'The Perfection', 'Arif V 216', 'Smallfoot', 'K.G.F: Chapter 1', 'Final Space', 'Summer of 84', 'The Guernsey Literary and Potato Peel Pie Society', 'The Protector', 'The Open House', 'Stan & Ollie', 'Mute', 'Under the Silver Lake', 'Operation Finale', 'Winchester', 'Safe', 'Boy Erased', 'Replicas', 'Succession', 'Holmes & Watson', 'The 15:17 to Paris', 'The Titan', 'The Darkest Minds', 'Todos lo saben', 'The Nutcracker and the Four Realms', 'Padmaavat', 'Escape Plan 2: Hades', 'The Hate U Give', \"Dumplin'\", 'Good Girls', 'The Rain', 'Braven', 'Stree', 'The Strangers: Prey at Night', 'They Shall Not Grow Old', 'Gringo', 'Badhaai ho', '22 July', \"At Eternity's Gate\", 'Game Over, Man!', 'Mirzapur', 'Tau', 'Slender Man', 'High Life', 'Sahsiyet', 'Blindspotting', 'Book Club', 'White Boy Rick', 'Nada a Perder', 'Cam', 'Super Troopers 2', 'A Discovery of Witches', 'Raazi', 'Destroyer', 'The Happytime Murders', 'Zero', 'Destination Wedding', 'Greta', 'Ghostland', 'Patrick Melrose', 'Three Identical Strangers', \"Won't You Be My Neighbor?\", 'Wild Wild Country', 'Gr√§ns', 'Tumbbad', 'Insatiable', 'The Kominsky Method', 'Dragon Ball Super: Broly', 'Midnight Sun', 'On the Basis of Sex', 'Wildlife', 'Second Act', 'Bao', '2.0', 'Dogman', 'Manifest', 'College Romance', 'Black Lightning', 'Parmanu: The Story of Pokhran', \"Evil Genius: The True Story of America's Most Diabolical Bank Heist\", \"Don't Worry, He Won't Get Far on Foot\", 'Unfriended: Dark Web', 'Calibre', 'Padman', 'The Outsider', 'The Professor', 'The Night Comes for Us', 'Sonu Ke Titu Ki Sweety', 'Early Man', '9-1-1', '√ñl√ºml√º D√ºnya', 'Traffik', 'The Princess Switch', 'Freaks', 'The Hurricane Heist', 'Beirut', 'Yeh Meri Family']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "first_5_pages = ['https://www.imdb.com/search/title/?release_date=2018&sort=num_votes,desc&page=1&ref_=adv_nxt',\n",
    "                 'https://www.imdb.com/search/title/?release_date=2018-01-01,2018-12-31&sort=num_votes,desc&start=51',\n",
    "                 'https://www.imdb.com/search/title/?release_date=2018-01-01,2018-12-31&sort=num_votes,desc&start=101',\n",
    "                 'https://www.imdb.com/search/title/?release_date=2018-01-01,2018-12-31&sort=num_votes,desc&start=151',\n",
    "                 'https://www.imdb.com/search/title/?release_date=2018-01-01,2018-12-31&sort=num_votes,desc&start=201']\n",
    "duration = []\n",
    "titles = []\n",
    "for i in first_5_pages :\n",
    "    res = requests.get(i)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    runtime = soup.find_all(class_ = 'runtime')\n",
    "    title = soup.find_all(class_ = 'lister-item-header')\n",
    "    \n",
    "    for j in runtime :\n",
    "        time = j.string\n",
    "        duration.append(int(re.search('\\d+', time).group()))\n",
    "        \n",
    "    for t in title :\n",
    "        titles.append(t.a.string)\n",
    "        \n",
    "print(duration)\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharp Objects 421\n"
     ]
    }
   ],
   "source": [
    "d = zip(titles,duration)\n",
    "sorted_titles = sorted(d, key = lambda kv: kv[1], reverse = True)[0]\n",
    "\n",
    "print(sorted_titles[0], sorted_titles[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharp Objects 421\n"
     ]
    }
   ],
   "source": [
    "# cn soln\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "from random import randint\n",
    "\n",
    "dict = {}\n",
    "\n",
    "for i in range(1,202,50) :\n",
    "    page = requests.get('https://www.imdb.com/search/title/?release_date=2018-01-01,2018-12-31&sort=num_votes,desc&start='\n",
    "                        + str(i) + '&ref_=adv_nxt')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    tags = soup.find_all(\"div\", class_ = \"lister-item\")\n",
    "    for j in tags:\n",
    "        if j.find(\"span\", class_ = \"runtime\" ) :\n",
    "            head = j.find(\"h3\", class_ = \"lister-item-header\")\n",
    "            dur = j.find(\"span\", class_ = \"runtime\")\n",
    "            t = int(dur.text.strip().split(\" \")[0])\n",
    "            dict[head.a.string] = t\n",
    "    time.sleep(randint(0,3))\n",
    "maxdur = -1\n",
    "maxname = 0\n",
    "for k,v in dict.items() :\n",
    "    if v > maxdur :\n",
    "        maxdur = v\n",
    "        maxname = k\n",
    "print(maxname, maxdur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications of AI\n",
    "\n",
    "From this website : https://en.wikipedia.org/wiki/Artificial_intelligence\n",
    "\n",
    "Find and print all applications of AI (As present in Contents of the page)\n",
    "\n",
    "Note : Print applications line wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthcare\n",
      "Automotive\n",
      "Finance and economics\n",
      "Cybersecurity\n",
      "Government\n",
      "Law-related professions\n",
      "Video games\n",
      "Military\n",
      "Hospitality\n",
      "Audit\n",
      "Advertising\n",
      "Art\n"
     ]
    }
   ],
   "source": [
    "## URL : https://en.wikipedia.org/wiki/Artificial_intelligence\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page = requests.get('https://en.wikipedia.org/wiki/Artificial_intelligence')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "li = soup.find(class_ = \"toclevel-1 tocsection-35\")\n",
    "applications = li.ul.find_all(\"span\", class_ = \"toctext\")\n",
    "\n",
    "for i in range(len(applications)) :\n",
    "    print(applications[i].string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image with maximum area\n",
    "\n",
    "From this website : https://en.wikipedia.org/wiki/Artificial_intelligence\n",
    "\n",
    "Find and print the src of the <img> tag which occupies the maximum area on the page.\n",
    "\n",
    "Note :\n",
    "\n",
    "Ignore images which doesn't have height or width attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//upload.wikimedia.org/wikipedia/commons/6/69/EM_Clustering_of_Old_Faithful_data.gif\n"
     ]
    }
   ],
   "source": [
    "## URL : https://en.wikipedia.org/wiki/Artificial_intelligence\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page = requests.get('https://en.wikipedia.org/wiki/Artificial_intelligence')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "images = soup.find_all(\"img\", class_ = \"thumbimage\")\n",
    "\n",
    "dict = {}\n",
    "for i in images:\n",
    "    area = (int(i['height']) * int(i['width']))\n",
    "    source = i['src']\n",
    "    dict[source] = area\n",
    "\n",
    "max_area = 0\n",
    "max_src = ''\n",
    "\n",
    "for k,v in dict.items() :\n",
    "    if v > max_area :\n",
    "        max_area = v\n",
    "        max_src = k\n",
    "\n",
    "print(max_src)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//upload.wikimedia.org/wikipedia/commons/thumb/8/87/Capek_play.jpg/220px-Capek_play.jpg\n"
     ]
    }
   ],
   "source": [
    "# cn soln\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page = requests.get('https://en.wikipedia.org/wiki/Artificial_intelligence')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "images = soup.find_all(\"img\")\n",
    "\n",
    "max_area = -1\n",
    "max_src = -1\n",
    "\n",
    "for i in images:\n",
    "    if i.has_attr('height') and i.has_attr('width') :\n",
    "        if int(i['height']) * int(i['width']) > max_area :\n",
    "            max_area = int(i['height']) * int(i['width'])\n",
    "            max_src = i['src']\n",
    "        max_src = k\n",
    "        \n",
    "print(max_src)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quotes with tag humor\n",
    "\n",
    "Find all the quotes that have the tag as \"humor\" from this website\n",
    "\n",
    "URL - http://quotes.toscrape.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÄúThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.‚Äù\n",
      "‚ÄúA day without sunshine is like, you know, night.‚Äù\n",
      "‚ÄúAnyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.‚Äù\n",
      "‚ÄúBeauty is in the eye of the beholder and it may be necessary from time to time to give a stupid or misinformed beholder a black eye.‚Äù\n",
      "‚ÄúAll you need is love. But a little chocolate now and then doesn't hurt.‚Äù\n",
      "‚ÄúRemember, we're madly in love, so it's all right to kiss me anytime you feel like it.‚Äù\n",
      "‚ÄúSome people never go crazy. What truly horrible lives they must lead.‚Äù\n",
      "‚ÄúThe trouble with having an open mind, of course, is that people will insist on coming along and trying to put things in it.‚Äù\n",
      "‚ÄúThink left and think right and think low and think high. Oh, the thinks you can think up if only you try!‚Äù\n",
      "‚ÄúThe reason I talk to myself is because I‚Äôm the only one whose answers I accept.‚Äù\n",
      "‚ÄúI am free of all prejudice. I hate everyone equally. ‚Äù\n",
      "‚ÄúA lady's imagination is very rapid; it jumps from admiration to love, from love to matrimony in a moment.‚Äù\n"
     ]
    }
   ],
   "source": [
    "## URL : http://quotes.toscrape.com/\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "    \n",
    "page = requests.get('http://quotes.toscrape.com/page/1/')\n",
    "base_url = 'http://quotes.toscrape.com'\n",
    "\n",
    "while page.status_code == 200 :\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    next_page = soup.find('li', class_ = 'next')\n",
    "    if next_page is None :\n",
    "        break\n",
    "    next_page_url = base_url + next_page.a['href']\n",
    "    \n",
    "    all_quotes = soup.find_all(\"div\", class_ = \"quote\")\n",
    "\n",
    "    for i in all_quotes :\n",
    "        tags = i.find('meta', class_ = \"keywords\")\n",
    "        if 'humor' in tags['content'] :\n",
    "            print(i.find('span', class_ = \"text\").string)\n",
    "            \n",
    "    page = requests.get(next_page_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÄúThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.‚Äù\n",
      "‚ÄúA day without sunshine is like, you know, night.‚Äù\n",
      "‚ÄúAnyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.‚Äù\n",
      "‚ÄúBeauty is in the eye of the beholder and it may be necessary from time to time to give a stupid or misinformed beholder a black eye.‚Äù\n",
      "‚ÄúAll you need is love. But a little chocolate now and then doesn't hurt.‚Äù\n",
      "‚ÄúRemember, we're madly in love, so it's all right to kiss me anytime you feel like it.‚Äù\n",
      "‚ÄúSome people never go crazy. What truly horrible lives they must lead.‚Äù\n",
      "‚ÄúThe trouble with having an open mind, of course, is that people will insist on coming along and trying to put things in it.‚Äù\n",
      "‚ÄúThink left and think right and think low and think high. Oh, the thinks you can think up if only you try!‚Äù\n",
      "‚ÄúThe reason I talk to myself is because I‚Äôm the only one whose answers I accept.‚Äù\n",
      "‚ÄúI am free of all prejudice. I hate everyone equally. ‚Äù\n",
      "‚ÄúA lady's imagination is very rapid; it jumps from admiration to love, from love to matrimony in a moment.‚Äù\n"
     ]
    }
   ],
   "source": [
    "# cn soln\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "    \n",
    "for i in range(1,3) :\n",
    "    \n",
    "    page = requests.get('http://quotes.toscrape.com/tag/humor/page/' + str(i) + '/')\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    for quote in soup.select(\".text\") :\n",
    "        print(quote.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print all authors\n",
    "\n",
    "Find and print the names of all the different authors from all pages of this website\n",
    "\n",
    "Note : Print the names of all authors line wise sorted in dictionary order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albert Einstein\n",
      "Alexandre Dumas fils\n",
      "Alfred Tennyson\n",
      "Allen Saunders\n",
      "Andr√© Gide\n",
      "Ayn Rand\n",
      "Bob Marley\n",
      "C.S. Lewis\n",
      "Charles Bukowski\n",
      "Charles M. Schulz\n",
      "Douglas Adams\n",
      "Dr. Seuss\n",
      "Eleanor Roosevelt\n",
      "Elie Wiesel\n",
      "Ernest Hemingway\n",
      "Friedrich Nietzsche\n",
      "Garrison Keillor\n",
      "George Bernard Shaw\n",
      "George Carlin\n",
      "George Eliot\n",
      "George R.R. Martin\n",
      "Haruki Murakami\n",
      "Helen Keller\n",
      "J.D. Salinger\n",
      "J.K. Rowling\n",
      "J.R.R. Tolkien\n",
      "James Baldwin\n",
      "Jane Austen\n",
      "Jim Henson\n",
      "John Lennon\n",
      "Jorge Luis Borges\n",
      "Marilyn Monroe\n",
      "Mark Twain\n",
      "Martin Luther King Jr.\n",
      "Mother Teresa\n",
      "Pablo Neruda\n",
      "Ralph Waldo Emerson\n",
      "Stephenie Meyer\n",
      "Steve Martin\n",
      "Suzanne Collins\n",
      "Terry Pratchett\n",
      "Thomas A. Edison\n",
      "W.C. Fields\n",
      "William Nicholson\n"
     ]
    }
   ],
   "source": [
    "# wrong answer - couse i calc page before , idk why this is wrong\n",
    "\n",
    "## URL : http://quotes.toscrape.com/\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "    \n",
    "page = requests.get('http://quotes.toscrape.com/page/1/')\n",
    "base_url = 'http://quotes.toscrape.com'\n",
    "\n",
    "all_authors = set()\n",
    "\n",
    "while page.status_code == 200 :\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    next_page = soup.find('li', class_ = 'next')\n",
    "    if next_page is None :\n",
    "        break\n",
    "    next_page_url = base_url + next_page.a['href']\n",
    "    \n",
    "    authors = soup.find_all(\"small\", class_ = \"author\")\n",
    "\n",
    "    for i in authors :\n",
    "        all_authors.add(i.string)\n",
    "        \n",
    "    page = requests.get(next_page_url)\n",
    "\n",
    "sorted_authors = sorted(all_authors)\n",
    "\n",
    "for i in sorted_authors:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albert Einstein\n",
      "Alexandre Dumas fils\n",
      "Alfred Tennyson\n",
      "Allen Saunders\n",
      "Andr√© Gide\n",
      "Ayn Rand\n",
      "Bob Marley\n",
      "C.S. Lewis\n",
      "Charles Bukowski\n",
      "Charles M. Schulz\n",
      "Douglas Adams\n",
      "Dr. Seuss\n",
      "E.E. Cummings\n",
      "Eleanor Roosevelt\n",
      "Elie Wiesel\n",
      "Ernest Hemingway\n",
      "Friedrich Nietzsche\n",
      "Garrison Keillor\n",
      "George Bernard Shaw\n",
      "George Carlin\n",
      "George Eliot\n",
      "George R.R. Martin\n",
      "Harper Lee\n",
      "Haruki Murakami\n",
      "Helen Keller\n",
      "J.D. Salinger\n",
      "J.K. Rowling\n",
      "J.M. Barrie\n",
      "J.R.R. Tolkien\n",
      "James Baldwin\n",
      "Jane Austen\n",
      "Jim Henson\n",
      "Jimi Hendrix\n",
      "John Lennon\n",
      "Jorge Luis Borges\n",
      "Khaled Hosseini\n",
      "Madeleine L'Engle\n",
      "Marilyn Monroe\n",
      "Mark Twain\n",
      "Martin Luther King Jr.\n",
      "Mother Teresa\n",
      "Pablo Neruda\n",
      "Ralph Waldo Emerson\n",
      "Stephenie Meyer\n",
      "Steve Martin\n",
      "Suzanne Collins\n",
      "Terry Pratchett\n",
      "Thomas A. Edison\n",
      "W.C. Fields\n",
      "William Nicholson\n"
     ]
    }
   ],
   "source": [
    "# right soln\n",
    "\n",
    "## URL : http://quotes.toscrape.com/\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "    \n",
    "page = requests.get('http://quotes.toscrape.com/page/1/')\n",
    "base_url = 'http://quotes.toscrape.com'\n",
    "\n",
    "all_authors = set()\n",
    "\n",
    "while page.status_code == 200 :\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    authors = soup.find_all(\"small\", class_ = \"author\")\n",
    "\n",
    "    for i in authors :\n",
    "        all_authors.add(i.string)\n",
    "    next_page = soup.find('li', class_ = 'next')\n",
    "    if next_page is None :\n",
    "        break\n",
    "    next_page_url = base_url + next_page.a['href']\n",
    "        \n",
    "    page = requests.get(next_page_url)\n",
    "\n",
    "sorted_authors = sorted(all_authors)\n",
    "\n",
    "for i in sorted_authors:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albert Einstein\n",
      "Alexandre Dumas fils\n",
      "Alfred Tennyson\n",
      "Allen Saunders\n",
      "Andr√© Gide\n",
      "Ayn Rand\n",
      "Bob Marley\n",
      "C.S. Lewis\n",
      "Charles Bukowski\n",
      "Charles M. Schulz\n",
      "Douglas Adams\n",
      "Dr. Seuss\n",
      "E.E. Cummings\n",
      "Eleanor Roosevelt\n",
      "Elie Wiesel\n",
      "Ernest Hemingway\n",
      "Friedrich Nietzsche\n",
      "Garrison Keillor\n",
      "George Bernard Shaw\n",
      "George Carlin\n",
      "George Eliot\n",
      "George R.R. Martin\n",
      "Harper Lee\n",
      "Haruki Murakami\n",
      "Helen Keller\n",
      "J.D. Salinger\n",
      "J.K. Rowling\n",
      "J.M. Barrie\n",
      "J.R.R. Tolkien\n",
      "James Baldwin\n",
      "Jane Austen\n",
      "Jim Henson\n",
      "Jimi Hendrix\n",
      "John Lennon\n",
      "Jorge Luis Borges\n",
      "Khaled Hosseini\n",
      "Madeleine L'Engle\n",
      "Marilyn Monroe\n",
      "Mark Twain\n",
      "Martin Luther King Jr.\n",
      "Mother Teresa\n",
      "Pablo Neruda\n",
      "Ralph Waldo Emerson\n",
      "Stephenie Meyer\n",
      "Steve Martin\n",
      "Suzanne Collins\n",
      "Terry Pratchett\n",
      "Thomas A. Edison\n",
      "W.C. Fields\n",
      "William Nicholson\n"
     ]
    }
   ],
   "source": [
    "# dm soln\n",
    "\n",
    "base_url='http://quotes.toscrape.com/'\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "first_url=\"http://quotes.toscrape.com/\"\n",
    "response=requests.get(first_url)\n",
    "authors=[]\n",
    "while response.status_code==200:\n",
    "    data=bs(response.text,'html.parser')\n",
    "    for i in data.find_all(class_=\"author\"):\n",
    "        authors.append(i.text)\n",
    "    if data.find(class_='next') is None:\n",
    "        break\n",
    "    k=data.find(class_='next')\n",
    "    x=k.a['href']\n",
    "    new=base_url+x\n",
    "        #print(new)\n",
    "    response=requests.get(new)\n",
    "auth=set()\n",
    "for i in authors:\n",
    "    auth.add(i)\n",
    "#for i in auth:\n",
    "#    print(i)\n",
    "sort=sorted(auth)\n",
    "for i in sort:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birth Date of authors\n",
    "\n",
    "Find the birth date of authors whose name start with 'J' from this website\n",
    "\n",
    "Note : Print a dictionary containing the name as key and the birth date as value.The Names of authors should be alphabetically sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'J.D. Salinger': 'January 01, 1919', 'J.K. Rowling': 'July 31, 1965', 'J.M. Barrie': 'May 09, 1860', 'J.R.R. Tolkien': 'January 03, 1892', 'James Baldwin': 'August 02, 1924', 'Jane Austen': 'December 16, 1775', 'Jim Henson': 'September 24, 1936', 'Jimi Hendrix': 'November 27, 1942', 'John Lennon': 'October 09, 1940', 'Jorge Luis Borges': 'August 24, 1899'}\n"
     ]
    }
   ],
   "source": [
    "## URL : http://quotes.toscrape.com/\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "    \n",
    "page = requests.get('http://quotes.toscrape.com/page/1/')\n",
    "base_url = 'http://quotes.toscrape.com'\n",
    "\n",
    "dict = {}\n",
    "while page.status_code == 200 :\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    quotes = soup.find_all(\"div\", class_ = \"quote\")    \n",
    "    for i in quotes :\n",
    "        author = i.find('small', class_ = 'author').string\n",
    "        if author.startswith('J') or author.startswith('j') :\n",
    "            res = requests.get('http://quotes.toscrape.com/' + i.find('a')['href'])\n",
    "            data = BeautifulSoup(res.text, 'html.parser')\n",
    "            birth_date = data.find('span', class_ = 'author-born-date').string\n",
    "            dict[author] = birth_date\n",
    "            \n",
    "    next_page = soup.find('li', class_ = 'next')\n",
    "    if next_page is None :\n",
    "        break\n",
    "    next_page_url = base_url + next_page.a['href']\n",
    "    page = requests.get(next_page_url)\n",
    "    \n",
    "sorted_dict = sorted(dict.items(), key = lambda kv: kv[0])\n",
    "d = {}\n",
    "for k,v in sorted_dict:\n",
    "    d[k] = v\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'J.D. Salinger': 'January 01, 1919', 'J.K. Rowling': 'July 31, 1965', 'J.M. Barrie': 'May 09, 1860', 'J.R.R. Tolkien': 'January 03, 1892', 'James Baldwin': 'August 02, 1924', 'Jane Austen': 'December 16, 1775', 'Jim Henson': 'September 24, 1936', 'Jimi Hendrix': 'November 27, 1942', 'John Lennon': 'October 09, 1940', 'Jorge Luis Borges': 'August 24, 1899'}\n"
     ]
    }
   ],
   "source": [
    "# dm soln \n",
    "# cn soln\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from random import randint\n",
    "authors = {} #Dictionary to find the links of author pages whose name starts with J\n",
    "for i in range(1,11) :\n",
    "    page = requests.get(\"http://quotes.toscrape.com/page/\"+ str(i) +\"/\")\n",
    "    soup = BeautifulSoup(page.content,'html.parser')\n",
    "    for aut in soup.select(\".author\") :\n",
    "        if aut.text[0] == \"J\" : #Finding all authors whose name starts with J\n",
    "            authors[aut.text] = aut.next_sibling.next_sibling['href'] #Saving the link\n",
    "bdate = {}\n",
    "for author in sorted(authors) :\n",
    "    page = requests.get(\"http://quotes.toscrape.com\"+ authors[author]) #Appending the  relative link to the page link\n",
    "   \n",
    "    soup = BeautifulSoup(page.content,'html.parser')\n",
    "    for i in soup.select(\".author-born-date\") :\n",
    "        bdate[author] = i.text\n",
    "print(bdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quotes by Albert Einstein\n",
    "\n",
    "Find all the quotes by Albert Einstein(in the order they appear on the page) from this website\n",
    "\n",
    "URL : http://quotes.toscrape.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÄúThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.‚Äù\n",
      "‚ÄúThere are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.‚Äù\n",
      "‚ÄúTry not to become a man of success. Rather become a man of value.‚Äù\n",
      "‚ÄúIf you can't explain it to a six year old, you don't understand it yourself.‚Äù\n",
      "‚ÄúIf you want your children to be intelligent, read them fairy tales. If you want them to be more intelligent, read them more fairy tales.‚Äù\n",
      "‚ÄúLogic will get you from A to Z; imagination will get you everywhere.‚Äù\n",
      "‚ÄúAny fool can know. The point is to understand.‚Äù\n",
      "‚ÄúLife is like riding a bicycle. To keep your balance, you must keep moving.‚Äù\n",
      "‚ÄúIf I were not a physicist, I would probably be a musician. I often think in music. I live my daydreams in music. I see my life in terms of music.‚Äù\n",
      "‚ÄúAnyone who has never made a mistake has never tried anything new.‚Äù\n"
     ]
    }
   ],
   "source": [
    "## URL : http://quotes.toscrape.com/\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "    \n",
    "page = requests.get('http://quotes.toscrape.com/page/1/')\n",
    "base_url = 'http://quotes.toscrape.com'\n",
    "\n",
    "while page.status_code == 200 :\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    next_page = soup.find('li', class_ = 'next')\n",
    "    if next_page is None :\n",
    "        break\n",
    "    next_page_url = base_url + next_page.a['href']\n",
    "    \n",
    "    all_quotes = soup.find_all(\"div\", class_ = \"quote\")\n",
    "\n",
    "    for i in all_quotes :\n",
    "        author = i.find('small', class_ = \"author\")\n",
    "        if 'Albert Einstein' in author.string :\n",
    "            print(i.find('span', class_ = \"text\").string)\n",
    "            \n",
    "    page = requests.get(next_page_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
